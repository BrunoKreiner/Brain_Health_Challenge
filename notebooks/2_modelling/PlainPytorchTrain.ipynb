{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "441884c9-1721-4a73-9bc1-0a5949a3f191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torchio as tio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, utils\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, Sampler\n",
    "\n",
    "sys.path.insert(0, '../../models/')\n",
    "sys.path.insert(0, '../../scripts/')\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "from helpers import miscellaneous as misc\n",
    "from helpers import plotters\n",
    "from helpers import preprocessing\n",
    "CONFIG = misc.get_config()\n",
    "\n",
    "from ModelUtils import EncoderCNN\n",
    "from ModelUtils import CognitiveTestMLP\n",
    "from ModelUtils import FusionModel\n",
    "\n",
    "#get Loader.py\n",
    "from Loader import MRIDataset\n",
    "\n",
    "#get TrainUtils.py helpers\n",
    "from TrainUtils import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea79a6e4-dc87-41c3-8aa6-20e6cc929967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "idx_to_label = {\n",
    "    'CN': 0,\n",
    "    'MCI': 1,\n",
    "    'AD': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50dee4b9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#transforms = None # equals no image pre-processing\n",
    "preprocessor = preprocessing.ADNIPreprocessing(CONFIG)\n",
    "#transforms = transforms.Compose([preprocessor.normalise()])\n",
    "\n",
    "# Initialize Image Transformation for model\n",
    "transforms = (\n",
    "    tio.CropOrPad((50, 50, 50)),\n",
    "    tio.RescaleIntensity(out_min_max=(-1, 1), in_min_max=(-1000, 1000))\n",
    ")\n",
    "transforms = tio.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c38ae616-6cc0-4c8b-a625-0851fc78ff1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length dataset:  1699\n"
     ]
    }
   ],
   "source": [
    "# Set paths to results\n",
    "# Add this to config file\n",
    "metrics_path = CONFIG['METRICS_DIR']\n",
    "saved_models_path = CONFIG['SERIALIZED_MODELS']\n",
    "\n",
    "#get dataset \n",
    "#change parameters to match config file\n",
    "dataset = MRIDataset(\"../../\" + CONFIG['TRAIN_LABELS_DIR'], transform = transforms)\n",
    "\n",
    "#return dataloader with given parameters\n",
    "train_loader = DataLoader(\n",
    "    dataset = dataset,\n",
    "    batch_size = 64, \n",
    "    num_workers = 4, \n",
    "    shuffle = True,\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "learning_rate = 0.01\n",
    "max_epochs = 1\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear) or isinstance(m, nn.Conv3d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "# Initialize Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "model = EncoderCNN(3).to(device)\n",
    "model.apply(weights_init)\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "print(\"length dataset: \", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a2971-af81-4453-9af8-e2e3555f6c3d",
   "metadata": {},
   "source": [
    "Process until it starts training is really long. So maybe another approach is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4ca771-a023-4e62-9139-32418799f516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch\n",
      "tensor([[0.4056, 0.2098, 0.3846],\n",
      "        [0.2117, 0.4670, 0.3212],\n",
      "        [0.2620, 0.0682, 0.6697],\n",
      "        [0.1376, 0.1209, 0.7415],\n",
      "        [0.1707, 0.4886, 0.3406],\n",
      "        [0.4268, 0.2581, 0.3152],\n",
      "        [0.2629, 0.2692, 0.4679],\n",
      "        [0.7818, 0.0556, 0.1625],\n",
      "        [0.4963, 0.0534, 0.4503],\n",
      "        [0.0656, 0.0250, 0.9095],\n",
      "        [0.5628, 0.2779, 0.1593],\n",
      "        [0.3048, 0.5302, 0.1650],\n",
      "        [0.0782, 0.6126, 0.3092],\n",
      "        [0.0823, 0.4390, 0.4787],\n",
      "        [0.2292, 0.2659, 0.5049],\n",
      "        [0.6338, 0.0225, 0.3438],\n",
      "        [0.2217, 0.4511, 0.3272],\n",
      "        [0.4621, 0.1354, 0.4026],\n",
      "        [0.5247, 0.3514, 0.1239],\n",
      "        [0.3665, 0.3495, 0.2840],\n",
      "        [0.0739, 0.5035, 0.4226],\n",
      "        [0.2697, 0.1994, 0.5309],\n",
      "        [0.4499, 0.0570, 0.4931],\n",
      "        [0.2960, 0.5480, 0.1560],\n",
      "        [0.1255, 0.1203, 0.7542],\n",
      "        [0.5975, 0.3464, 0.0561],\n",
      "        [0.2270, 0.3029, 0.4702],\n",
      "        [0.2789, 0.4637, 0.2573],\n",
      "        [0.1364, 0.6857, 0.1779],\n",
      "        [0.6806, 0.0796, 0.2398],\n",
      "        [0.1403, 0.5724, 0.2872],\n",
      "        [0.0925, 0.1450, 0.7625],\n",
      "        [0.1825, 0.2029, 0.6146],\n",
      "        [0.3046, 0.0592, 0.6363],\n",
      "        [0.1223, 0.3381, 0.5396],\n",
      "        [0.2298, 0.0601, 0.7101],\n",
      "        [0.3909, 0.4575, 0.1517],\n",
      "        [0.4279, 0.2846, 0.2876],\n",
      "        [0.0810, 0.7523, 0.1667],\n",
      "        [0.0559, 0.8609, 0.0832],\n",
      "        [0.2347, 0.5490, 0.2163],\n",
      "        [0.5137, 0.2772, 0.2091],\n",
      "        [0.1180, 0.2876, 0.5944],\n",
      "        [0.3726, 0.2542, 0.3732],\n",
      "        [0.5406, 0.4103, 0.0491],\n",
      "        [0.8349, 0.1512, 0.0139],\n",
      "        [0.7124, 0.2256, 0.0620],\n",
      "        [0.4900, 0.2466, 0.2634],\n",
      "        [0.0977, 0.8379, 0.0644],\n",
      "        [0.2343, 0.3519, 0.4138],\n",
      "        [0.1223, 0.7885, 0.0891],\n",
      "        [0.2174, 0.2288, 0.5538],\n",
      "        [0.2460, 0.6056, 0.1484],\n",
      "        [0.6579, 0.2153, 0.1268],\n",
      "        [0.0858, 0.5190, 0.3951],\n",
      "        [0.6729, 0.3114, 0.0157],\n",
      "        [0.1135, 0.5173, 0.3692],\n",
      "        [0.5017, 0.4170, 0.0813],\n",
      "        [0.3285, 0.1169, 0.5546],\n",
      "        [0.1705, 0.7350, 0.0945],\n",
      "        [0.1927, 0.5512, 0.2561],\n",
      "        [0.4416, 0.3673, 0.1911],\n",
      "        [0.4738, 0.0850, 0.4412],\n",
      "        [0.2865, 0.1771, 0.5364]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([2, 2, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        2, 2, 1, 1, 0, 1, 0, 1, 1, 2, 0, 2, 1, 1, 0, 0, 2, 1, 1, 1, 0, 2, 1, 2,\n",
      "        1, 1, 0, 1, 1, 1, 1, 2, 0, 1, 1, 2, 1, 2, 1, 1], device='cuda:0')\n",
      "tensor([[0.3722, 0.2732, 0.3546],\n",
      "        [0.0896, 0.6812, 0.2292],\n",
      "        [0.1528, 0.0512, 0.7960],\n",
      "        [0.3652, 0.2277, 0.4071],\n",
      "        [0.1745, 0.5803, 0.2451],\n",
      "        [0.1909, 0.5475, 0.2615],\n",
      "        [0.0288, 0.9121, 0.0591],\n",
      "        [0.3616, 0.2582, 0.3802],\n",
      "        [0.8212, 0.0943, 0.0845],\n",
      "        [0.2015, 0.4857, 0.3129],\n",
      "        [0.3377, 0.5387, 0.1236],\n",
      "        [0.1731, 0.3423, 0.4846],\n",
      "        [0.1504, 0.3707, 0.4789],\n",
      "        [0.6717, 0.2548, 0.0735],\n",
      "        [0.6519, 0.2668, 0.0813],\n",
      "        [0.1088, 0.4598, 0.4314],\n",
      "        [0.8816, 0.0334, 0.0850],\n",
      "        [0.4040, 0.0091, 0.5869],\n",
      "        [0.1761, 0.0259, 0.7981],\n",
      "        [0.3927, 0.0508, 0.5564],\n",
      "        [0.0543, 0.8537, 0.0920],\n",
      "        [0.4682, 0.2171, 0.3147],\n",
      "        [0.3579, 0.5035, 0.1387],\n",
      "        [0.2521, 0.3479, 0.4000],\n",
      "        [0.0811, 0.5394, 0.3795],\n",
      "        [0.6432, 0.1256, 0.2312],\n",
      "        [0.2248, 0.1576, 0.6176],\n",
      "        [0.0132, 0.9510, 0.0358],\n",
      "        [0.8466, 0.0505, 0.1030],\n",
      "        [0.1191, 0.5409, 0.3400],\n",
      "        [0.2525, 0.3470, 0.4005],\n",
      "        [0.0808, 0.5970, 0.3222],\n",
      "        [0.3232, 0.4290, 0.2478],\n",
      "        [0.3381, 0.5518, 0.1101],\n",
      "        [0.6380, 0.2613, 0.1007],\n",
      "        [0.1969, 0.5901, 0.2129],\n",
      "        [0.0383, 0.7059, 0.2558],\n",
      "        [0.3272, 0.0203, 0.6525],\n",
      "        [0.5445, 0.0191, 0.4363],\n",
      "        [0.1675, 0.4129, 0.4196],\n",
      "        [0.0272, 0.9001, 0.0727],\n",
      "        [0.3130, 0.3828, 0.3042],\n",
      "        [0.3910, 0.5626, 0.0464],\n",
      "        [0.1443, 0.5105, 0.3452],\n",
      "        [0.3328, 0.1362, 0.5310],\n",
      "        [0.1322, 0.5248, 0.3430],\n",
      "        [0.2707, 0.4031, 0.3262],\n",
      "        [0.7078, 0.1928, 0.0994],\n",
      "        [0.6071, 0.0291, 0.3637],\n",
      "        [0.0373, 0.8829, 0.0798],\n",
      "        [0.2245, 0.3936, 0.3819],\n",
      "        [0.4223, 0.1034, 0.4743],\n",
      "        [0.2159, 0.4315, 0.3526],\n",
      "        [0.7103, 0.0864, 0.2032],\n",
      "        [0.2780, 0.4378, 0.2842],\n",
      "        [0.2394, 0.5319, 0.2287],\n",
      "        [0.0964, 0.6102, 0.2934],\n",
      "        [0.3490, 0.5095, 0.1415],\n",
      "        [0.9824, 0.0033, 0.0143],\n",
      "        [0.0289, 0.9040, 0.0671],\n",
      "        [0.2165, 0.7175, 0.0660],\n",
      "        [0.7461, 0.1025, 0.1514],\n",
      "        [0.1141, 0.0272, 0.8586],\n",
      "        [0.2580, 0.0395, 0.7025]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([1, 1, 0, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 2, 0, 1, 0, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1, 0, 2, 1, 1, 0,\n",
      "        2, 1, 0, 2, 0, 1, 0, 0, 1, 1, 1, 1, 2, 1, 2, 0], device='cuda:0')\n",
      "tensor([[0.1892, 0.3786, 0.4322],\n",
      "        [0.2012, 0.1259, 0.6729],\n",
      "        [0.2149, 0.2655, 0.5196],\n",
      "        [0.0484, 0.7906, 0.1610],\n",
      "        [0.1727, 0.5389, 0.2884],\n",
      "        [0.0558, 0.8422, 0.1021],\n",
      "        [0.1506, 0.6506, 0.1988],\n",
      "        [0.1354, 0.0074, 0.8572],\n",
      "        [0.3229, 0.3453, 0.3318],\n",
      "        [0.7347, 0.0826, 0.1827],\n",
      "        [0.7069, 0.1689, 0.1242],\n",
      "        [0.4304, 0.2464, 0.3232],\n",
      "        [0.4382, 0.4176, 0.1442],\n",
      "        [0.1396, 0.7272, 0.1332],\n",
      "        [0.2788, 0.1971, 0.5241],\n",
      "        [0.2497, 0.5110, 0.2393],\n",
      "        [0.2056, 0.5229, 0.2714],\n",
      "        [0.2073, 0.4978, 0.2949],\n",
      "        [0.2307, 0.0663, 0.7031],\n",
      "        [0.6456, 0.1376, 0.2168],\n",
      "        [0.2373, 0.5073, 0.2554],\n",
      "        [0.4530, 0.0181, 0.5288],\n",
      "        [0.2452, 0.4431, 0.3117],\n",
      "        [0.9073, 0.0145, 0.0782],\n",
      "        [0.1881, 0.4697, 0.3422],\n",
      "        [0.5190, 0.0255, 0.4555],\n",
      "        [0.1166, 0.7904, 0.0930],\n",
      "        [0.5659, 0.3231, 0.1110],\n",
      "        [0.2442, 0.5349, 0.2209],\n",
      "        [0.1826, 0.6239, 0.1934],\n",
      "        [0.1253, 0.7699, 0.1049],\n",
      "        [0.1495, 0.6715, 0.1790],\n",
      "        [0.1841, 0.5530, 0.2629],\n",
      "        [0.1384, 0.6416, 0.2200],\n",
      "        [0.6366, 0.1343, 0.2291],\n",
      "        [0.1241, 0.5712, 0.3048],\n",
      "        [0.7943, 0.0113, 0.1944],\n",
      "        [0.1787, 0.4475, 0.3738],\n",
      "        [0.4675, 0.2185, 0.3139],\n",
      "        [0.1489, 0.5532, 0.2979],\n",
      "        [0.1722, 0.6233, 0.2045],\n",
      "        [0.2361, 0.5882, 0.1756],\n",
      "        [0.3032, 0.4782, 0.2186],\n",
      "        [0.0832, 0.8021, 0.1147],\n",
      "        [0.6666, 0.1881, 0.1453],\n",
      "        [0.1914, 0.3272, 0.4814],\n",
      "        [0.3026, 0.2939, 0.4035],\n",
      "        [0.2166, 0.0015, 0.7819],\n",
      "        [0.0976, 0.5704, 0.3320],\n",
      "        [0.6175, 0.0890, 0.2935],\n",
      "        [0.6465, 0.1431, 0.2104],\n",
      "        [0.0885, 0.8156, 0.0959],\n",
      "        [0.0988, 0.7602, 0.1410],\n",
      "        [0.1467, 0.5137, 0.3396],\n",
      "        [0.6922, 0.0028, 0.3050],\n",
      "        [0.1369, 0.7488, 0.1142],\n",
      "        [0.7943, 0.0113, 0.1944],\n",
      "        [0.3024, 0.5893, 0.1083],\n",
      "        [0.2200, 0.0745, 0.7055],\n",
      "        [0.1812, 0.4340, 0.3848],\n",
      "        [0.0666, 0.8845, 0.0489],\n",
      "        [0.0268, 0.9216, 0.0516],\n",
      "        [0.3419, 0.5769, 0.0812],\n",
      "        [0.3677, 0.2078, 0.4244]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([0, 0, 0, 1, 1, 2, 0, 1, 1, 0, 1, 2, 0, 1, 1, 2, 2, 1, 2, 1, 0, 1, 1, 1,\n",
      "        0, 1, 2, 1, 1, 0, 2, 0, 1, 1, 0, 1, 2, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1,\n",
      "        1, 1, 2, 1, 0, 1, 2, 2, 2, 0, 1, 1, 1, 2, 1, 2], device='cuda:0')\n",
      "tensor([[0.0948, 0.7153, 0.1899],\n",
      "        [0.0790, 0.8416, 0.0794],\n",
      "        [0.4127, 0.0021, 0.5852],\n",
      "        [0.3050, 0.3657, 0.3293],\n",
      "        [0.2700, 0.3604, 0.3696],\n",
      "        [0.1122, 0.8003, 0.0875],\n",
      "        [0.1632, 0.7157, 0.1211],\n",
      "        [0.0907, 0.7632, 0.1461],\n",
      "        [0.3529, 0.2843, 0.3628],\n",
      "        [0.2396, 0.4839, 0.2766],\n",
      "        [0.0227, 0.9384, 0.0389],\n",
      "        [0.2479, 0.5284, 0.2238],\n",
      "        [0.2085, 0.4141, 0.3775],\n",
      "        [0.2896, 0.4745, 0.2359],\n",
      "        [0.2923, 0.4720, 0.2357],\n",
      "        [0.1801, 0.5391, 0.2808],\n",
      "        [0.2409, 0.3483, 0.4108],\n",
      "        [0.2923, 0.4720, 0.2357],\n",
      "        [0.6230, 0.1005, 0.2764],\n",
      "        [0.4308, 0.3199, 0.2493],\n",
      "        [0.1716, 0.4748, 0.3536],\n",
      "        [0.4851, 0.1432, 0.3717],\n",
      "        [0.3725, 0.4118, 0.2157],\n",
      "        [0.0597, 0.8288, 0.1115],\n",
      "        [0.6135, 0.0390, 0.3475],\n",
      "        [0.3029, 0.5327, 0.1643],\n",
      "        [0.6084, 0.1016, 0.2899],\n",
      "        [0.6002, 0.0334, 0.3664],\n",
      "        [0.2308, 0.6739, 0.0952],\n",
      "        [0.6653, 0.0900, 0.2447],\n",
      "        [0.2352, 0.4274, 0.3375],\n",
      "        [0.0765, 0.8013, 0.1221],\n",
      "        [0.3659, 0.3230, 0.3111],\n",
      "        [0.4149, 0.2855, 0.2996],\n",
      "        [0.1537, 0.6566, 0.1896],\n",
      "        [0.3057, 0.4593, 0.2349],\n",
      "        [0.4036, 0.0028, 0.5936],\n",
      "        [0.3166, 0.3992, 0.2842],\n",
      "        [0.4535, 0.2459, 0.3006],\n",
      "        [0.1385, 0.5834, 0.2781],\n",
      "        [0.1758, 0.5752, 0.2490],\n",
      "        [0.3807, 0.2048, 0.4144],\n",
      "        [0.0514, 0.8892, 0.0593],\n",
      "        [0.2897, 0.4219, 0.2884],\n",
      "        [0.1155, 0.7713, 0.1132],\n",
      "        [0.3717, 0.2403, 0.3879],\n",
      "        [0.5006, 0.1182, 0.3812],\n",
      "        [0.2214, 0.4513, 0.3273],\n",
      "        [0.1802, 0.5979, 0.2219],\n",
      "        [0.1680, 0.6111, 0.2209],\n",
      "        [0.0841, 0.7958, 0.1202],\n",
      "        [0.3800, 0.1755, 0.4445],\n",
      "        [0.4480, 0.2494, 0.3026],\n",
      "        [0.1283, 0.7626, 0.1090],\n",
      "        [0.1413, 0.7005, 0.1582],\n",
      "        [0.3058, 0.0032, 0.6910],\n",
      "        [0.2054, 0.5371, 0.2574],\n",
      "        [0.0514, 0.8852, 0.0634],\n",
      "        [0.3340, 0.0030, 0.6630],\n",
      "        [0.5976, 0.1062, 0.2962],\n",
      "        [0.3899, 0.0055, 0.6046],\n",
      "        [0.5972, 0.0286, 0.3742],\n",
      "        [0.5061, 0.2934, 0.2004],\n",
      "        [0.2739, 0.5006, 0.2256]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([1, 0, 0, 2, 2, 2, 0, 1, 0, 0, 1, 1, 0, 1, 2, 2, 1, 2, 0, 1, 2, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 0, 2, 0, 0, 1, 0, 1, 2,\n",
      "        2, 1, 0, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([2, 0, 1, 2, 1, 1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 0, 1,\n",
      "        0, 2, 1, 2, 2, 1, 0, 0, 1, 1, 1, 0, 1, 2, 0, 1, 1, 1, 2, 1, 2, 1, 2, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 2, 1, 2, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([0, 1, 2, 1, 1, 1, 2, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 0,\n",
      "        1, 1, 2, 2, 1, 1, 1, 0, 1, 2, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([0, 2, 2, 1, 2, 1, 1, 0, 0, 1, 0, 2, 2, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 0,\n",
      "        1, 0, 2, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 1, 1, 2, 1, 0, 2,\n",
      "        0, 1, 0, 0, 0, 1, 2, 2, 0, 0, 1, 1, 2, 1, 0, 1], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 2, 2, 0, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1, 1, 2, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 2, 2, 0], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([2, 2, 2, 0, 1, 0, 2, 0, 0, 1, 2, 2, 0, 1, 1, 2, 2, 1, 1, 2, 0, 0, 1, 0,\n",
      "        0, 2, 1, 0, 0, 2, 1, 1, 0, 1, 1, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 2,\n",
      "        1, 2, 2, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 2, 1, 1], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([1, 2, 1, 0, 0, 2, 1, 1, 1, 2, 0, 1, 1, 1, 1, 0, 2, 0, 1, 0, 1, 1, 0, 2,\n",
      "        1, 1, 1, 0, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        2, 1, 1, 0, 1, 1, 1, 2, 2, 0, 2, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([2, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 0,\n",
      "        0, 2, 2, 0, 0, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1,\n",
      "        2, 1, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([0, 0, 1, 1, 0, 0, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 2, 1,\n",
      "        1, 1, 0, 0, 0, 1, 1, 2, 1, 0, 1, 2, 1, 1, 0, 0, 2, 0, 0, 1, 1, 0, 2, 0,\n",
      "        0, 1, 1, 2, 2, 0, 1, 2, 0, 2, 1, 1, 1, 2, 1, 1], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([2, 0, 1, 0, 1, 2, 0, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 2, 1, 2,\n",
      "        1, 0, 0, 0, 2, 1, 1, 2, 1, 0, 0, 1, 0, 2, 1, 1, 1, 1, 0, 2, 2, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 1, 1, 0, 2, 0, 0, 2, 1, 2, 1, 1], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([1, 1, 1, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 2, 1, 1, 1, 1, 0, 0, 2, 0, 0, 1, 2, 0, 2, 1, 1, 2,\n",
      "        2, 1, 0, 0, 1, 2, 2, 2, 0, 0, 1, 0, 0, 0, 0, 2], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([0, 0, 1, 0, 0, 2, 1, 2, 1, 2, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 1,\n",
      "        1, 1, 2, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 2, 1], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([0, 0, 2, 2, 2, 2, 2, 2, 1, 0, 1, 0, 0, 0, 1, 1, 0, 2, 1, 1, 1, 0, 0, 0,\n",
      "        1, 1, 1, 0, 0, 2, 2, 0, 0, 2, 2, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0, 0, 2, 1, 1, 1], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([0, 0, 0, 1, 1, 2, 1, 0, 2, 2, 0, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 0, 0, 1,\n",
      "        2, 0, 1, 1, 0, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 0, 1, 2, 1, 1,\n",
      "        1, 0, 0, 2, 1, 1, 2, 2, 1, 2, 2, 0, 0, 0, 1, 2], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([1, 0, 0, 0, 1, 2, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1,\n",
      "        2, 1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 0, 1, 1, 1, 2, 0, 1, 0, 2, 0, 0, 0, 2,\n",
      "        1, 1, 0, 1, 2, 0, 2, 2, 2, 0, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([0, 0, 0, 1, 0, 2, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 0, 2, 1,\n",
      "        1, 1, 1, 2, 1, 1, 0, 2, 0, 1, 1, 1, 0, 0, 2, 1, 0, 0, 1, 2, 1, 1, 1, 2,\n",
      "        2, 2, 0, 1, 2, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 0], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 0, 2, 2, 0, 1, 1, 0, 1, 2, 1, 1, 2,\n",
      "        0, 2, 0, 1, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 2, 0, 0, 2, 1, 1, 2, 2, 0,\n",
      "        1, 2, 1, 0, 0, 2, 1, 1, 2, 1, 0, 0, 2, 0, 2, 0], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([0, 2, 1, 1, 0, 1, 1, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 2, 1, 0, 1, 0, 2, 2, 1, 1, 1, 0, 0, 0, 0, 2, 2, 1, 1, 0, 1, 0, 1, 2,\n",
      "        1, 1, 1, 2, 0, 2, 1, 1, 0, 2, 2, 2, 0, 1, 1, 0], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 0, 2, 2, 0, 0, 1, 1, 2, 2, 1, 0, 1,\n",
      "        0, 2, 2, 1, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 1, 2, 1, 2, 0, 0,\n",
      "        1, 1, 1, 2, 2, 1, 0, 1, 1, 2, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([2, 2, 0, 2, 2, 2, 2, 1, 0, 0, 1, 1, 1, 1, 0, 2, 1, 2, 1, 1, 0, 1, 2, 1,\n",
      "        0, 0, 1, 1, 1, 0, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 2, 2, 1,\n",
      "        0, 0, 0, 1, 0, 0, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([1, 2, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 2, 0,\n",
      "        1, 1, 0, 2, 2, 1, 1, 2, 1, 2, 0, 1, 1, 0, 2, 0, 0, 1, 1, 1, 0, 0, 2, 2,\n",
      "        1, 0, 2, 0, 2, 1, 1, 0, 2, 0, 0, 2, 2, 1, 1, 2], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([1, 2, 1, 2, 1, 1, 0, 0, 1, 1, 2, 1, 0, 0, 1, 1, 0, 1, 1, 2, 0, 2, 2, 0,\n",
      "        0, 0, 0, 2, 0, 0, 1, 0, 1, 2, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1,\n",
      "        2, 1, 1, 1, 0, 2, 1, 1, 0, 0, 2, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([1, 0, 1, 1, 2, 0, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 0, 1, 2, 2, 1,\n",
      "        1, 0, 0, 1, 0, 2, 2, 2, 2, 1, 0, 0, 1, 2, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 0, 0], device='cuda:0')\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([1, 1, 1, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 1, 1, 0, 1, 0, 0, 2, 1, 0, 2, 1,\n",
      "        2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 0], device='cuda:0')\n",
      "Train Epoch Finished\n",
      "Epoch: [1/1], average total train loss: nan, train epoch time (s): [206.32820105552673], average validation loss: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# Train model\n",
    "results = train(train_loader, model, optimizer, max_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e80dac-c00c-4d53-8020-1bf9a7c43be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "run_name = \"TEST-NeuronFusionExcessiveGigaNet-18\"\n",
    "results.to_csv(\"../../\" + metrics_path + run_name + \".csv\", index=False)\n",
    "torch.save(model, \"../../\" + saved_models_path + run_name + \".pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
